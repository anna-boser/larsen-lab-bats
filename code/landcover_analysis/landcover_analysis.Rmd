---
title: "Land Cover Analysis for Bat Presence"
author: "D. Nākoa Farrant"
date: "2022-10-21"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(stars) # ʻstarsʻ requires 'sf' 0.9.8 was found, but >= 1.0.3
library(sf)
library(raster) # used to resample FVEG raster with "ngb" method
library(terra)
library(nngeo) # to remove holes from polygons
library(exactextractr) # extract bat occurrence in the land cover polygons
```

# Read in bat study site and bat occurrence data
```{r}
# polygon with the extent of the study region
bat_study_area <- st_read("~/Documents/github/larsen-lab-bats/data/landcover_analysis/bats/bats_study_area/bats_study_area.shp") %>% 
  st_transform(st_crs(3310)) %>% 
  st_make_valid()

# WGS84 projection of the raw bats
#bat_raw <- rast("~/Documents/github/larsen-lab-bats/data/landcover_analysis/bats/2017_aggregate_2017.tif") 
# WGS84 projection of the exponentially corrected bat layer
bat_exp <- rast("~/Documents/github/larsen-lab-bats/data/landcover_analysis/bats/bats_exponential_corrected_2017.tif") 

#bat_raw_NAD83 <- project(bat_raw, "epsg:3310")
bat_exp_NAD83 <- project(bat_exp, "epsg:3310")
```


# Read in FVEG data
```{r}
# fveg from CALFIRE FRAP
# https://map.dfg.ca.gov/metadata/ds1327.html

# read into arcmap and then exported as a tif because had trouble reading the geodatabase in R
# create a new column that is equal to WHR13NAME except where WHRNUM has riparian values: 15 (Desert Riparian), 19, 37 (Montane Riparian), 56 (Valley Foothill Riparian)
# Use the Lookup tool to export the new column as a raster and read that in here
# start using the raster package instead of terra so you can resample with nearest neighbor method
fveg_raster <- rast("~/Documents/github/larsen-lab-bats/data/landcover_analysis/fveg/fveg_whr10num_ClipBats.tif")
```

```{r}
# resample fveg raster (30m) to the resolution of the bat data (70m) using the nearest neighbor method
# the nearest neighbor method treats the class code numbers in the FVEG raster as categorical variables
fveg_resample_ngb <- terra::resample(fveg_raster, bat_exp_NAD83, method = "near")

# convert the resampled raster to polygons in an SF object
fveg_resample_ngb_sf <- sf::as_Spatial(sf::st_as_sf(stars::st_as_stars(fveg_resample_ngb), as_points = FALSE, merge = T)) %>% 
  st_as_sf() %>% 
  st_make_valid()

st_write(fveg_resample_ngb_sf, "~/Documents/github/larsen-lab-bats/data/landcover_analysis/fveg/fveg_resample_ngb_sf.gpkg", append = F)
```

# Read in Land IQ crop data shapefile
```{r}
# Data IQ crop data from 2019 downloaded from https://data.cnra.ca.gov/dataset/statewide-crop-mapping
landIQ <- st_read("~/Documents/github/larsen-lab-bats/data/landcover_analysis/i15_Crop_Mapping_2019/i15_Crop_Mapping_2019.shp") %>% 
  st_transform(st_crs(3310)) %>%  # project into NAD83 / California Albers projection
  st_make_valid()

# Crop the extent of land IQ agricultural data to bat study area
landIQ_clip2bats <- st_crop(landIQ, bat_study_area)

# Read in a CSV dictionary to add SummerCropID and CropName associated with the CROPTYP2 column in the original landIQ dataset
# SummerCropID was a code that was assigned to each CROPTYP2 arbitrarily in alphabetical order. The CropName is derived from the metadata associated with each CROPTYP2 abbreviation  
SummerCropID_crosswalk <- read_csv("~/Documents/github/larsen-lab-bats/data/landcover_analysis/CSV_files/SummerCropID.csv")
landIQ_clip2bats_SummerCropID <- merge(landIQ_clip2bats, SummerCropID_crosswalk, by = "CROPTYP2")

# isolate a subset of columns of interest from the LandIQ data layer
landIQ_clip2bats_SummerCropID_sub <- landIQ_clip2bats_SummerCropID %>% 
  dplyr::select(UniqueID, CROPTYP2, CropName, SummerCropID)
```

```{r}
# Create a helper function to erase polygons (y) from another set of polygons (x)
st_erase <- function(x, y) st_difference(x, st_union(st_combine(y)))
```

```{r}
# took 4-5 hours to run using Apple M1 Pro chip, 16 GB, MacBook Pro 2021
fveg_WHR10_erase_landIQ <- st_erase(st_make_valid(fveg_resample_ngb_sf), st_make_valid(landIQ_clip2bats_SummerCropID_sub))

st_write(fveg_WHR10_erase_landIQ, "~/Documents/github/larsen-lab-bats/data/landcover_analysis/output_layers/fveg_WHR10_erase_landIQ.gpkg", append = F)
```

```{r}
fveg_WHR10_erase_landIQ <- fveg_WHR10_erase_landIQ %>% 
  rename(LC_ID = values)

landIQ_LCID <- landIQ_clip2bats_SummerCropID_sub %>% 
  mutate(LC_ID = SummerCropID) %>% 
  dplyr::select(LC_ID)

fveg_landIQ_bind <- rbind(fveg_WHR10_erase_landIQ, landIQ_LCID)

st_write(fveg_landIQ_bind, "~/Documents/github/larsen-lab-bats/data/landcover_analysis/output_layers/fveg_landIQ_bind.gpkg")
```

```{r}
# Read in a CSV dictionary of labels and codes for different land cover types
LC_newcode_labels <- read_csv("~/Documents/github/larsen-lab-bats/data/landcover_analysis/CSV_files/newcode_labels.csv")

fveg_landIQ_labeled <- merge(fveg_landIQ_bind, LC_newcode_labels, by = "LC_ID")

fveg_landIQ_labeled_summ <- fveg_landIQ_labeled %>% 
  group_by(NewCode) %>% 
  summarise()

fveg_landIQ_labeled_summ_vect <- vect(fveg_landIQ_labeled_summ)

# function specifying what data to extract from the bats raster
f <- function(x, na.rm = T) {
       c(mean=mean(x, na.rm = na.rm),
        sd=sd(x, na.rm = na.rm)
    )
}

# extract the average and SD of exponentially corrected bat presence values in each NewCode category and bind it to the existing SpatVect
extract_expBats_terra_NewCode_f <- cbind(fveg_landIQ_labeled_summ_vect, terra::extract(bat_exp_NAD83, fveg_landIQ_labeled_summ_vect, fun = f, na.rm=TRUE))

# Convert the results to a data frame
extract_expBats_terra_NewCode_f_df <- data.frame(extract_expBats_terra_NewCode_f)
```

```{r}
NewCode_map <- data.frame(
  NewCode = c(10, 20, 30, 40, 50, 60, 70, 80, 101, 110, 120, 130, 140),
  NewClass = c("Agriculture", "Barren_Other", "Conifer", "Desert", "Hardwood", "Herbaceous", "Shrub", "Urban", "Water_Wetland", "Fruits_Nuts_Vineyards", "Row_Field", "Grassland", "Rice")
)

extract_expBats_simple <- extract_expBats_terra_NewCode_f_df %>% 
  mutate(Mean = layer.mean, SD = layer.sd) %>% 
  dplyr::select(NewCode, Mean, SD)

extract_merge <- merge(extract_expBats_simple, NewCode_map, by = "NewCode")
```

```{r}
# calculate number of observation in each NewCode class to be used to calculate the Standard Error and 95% confidence interval
fveg_landIQ_labeled_ObsCount_df <- fveg_landIQ_labeled %>% 
  st_drop_geometry() %>% 
  group_by(NewCode) %>% 
  summarise(obs_count = n())
```

```{r}
extract_merge_obs <- merge(extract_merge, fveg_landIQ_labeled_ObsCount_df, by = "NewCode")

# calculate the Standard Error and 95% confidence interval
extract_merge_obs <- extract_merge_obs %>% 
  mutate(SE = SD/sqrt(obs_count), LC_95perc = 1.96*SE)
```

```{r}
fveg_landIQ_labeled_area <- fveg_landIQ_labeled
fveg_landIQ_labeled_area$area_m2 <- st_area(fveg_landIQ_labeled_area) %>% as.numeric()

fveg_landIQ_labeled_area_df <- fveg_landIQ_labeled_area %>% 
  st_drop_geometry() %>% 
  mutate(area_ha = area_m2/1e4) %>% 
  group_by(NewCode) %>% 
  summarise(ClassAreaHa = sum(area_ha, na.rm = T), SD_AreaHa = sd(area_ha, na.rm = T))
```

```{r}
fveg_landIQ_labeled_area_df <- fveg_landIQ_labeled_area %>% 
  st_drop_geometry() %>% 
  mutate(area_ha = area_m2/1e4) %>% 
  group_by(NewCode) %>% 
  summarise(MeanClassAreaHa = mean(area_ha, na.rm = T), ClassAreaHa = sum(area_ha, na.rm = T), SD_AreaHa = sd(area_ha, na.rm = T))
```


```{r}
area_merge <- merge(fveg_landIQ_labeled_area_df, NewCode_map, by = "NewCode")

area_merge_obs <- merge(area_merge, fveg_landIQ_labeled_ObsCount_df, by = "NewCode")

# calculate the Standard Error and 95% confidence interval
area_merge_obs <- area_merge_obs %>% 
  mutate(SE = SD_AreaHa/sqrt(obs_count), LC_95perc = 1.96*SE)
```


```{r}
# plot the total area for each of the land cover classes
total_area_merge_obs_p <- ggplot(data = area_merge_obs, aes(x = reorder(NewClass, ClassAreaHa), y = ClassAreaHa)) +
  geom_col() + 
  coord_flip() +
  labs(x = "Land Cover", y = "Total Area of Land Cover Classes (ha)") +
  theme_bw() +
  theme(panel.border = element_rect(colour = "black", fill=NA, size=1))

total_area_merge_obs_p

mean_area_merge_obs_p <- ggplot(data = area_merge_obs, aes(x = reorder(NewClass, MeanClassAreaHa), y = MeanClassAreaHa)) +
  geom_point() + 
  geom_errorbar(aes(ymin=MeanClassAreaHa-LC_95perc, ymax=MeanClassAreaHa+LC_95perc)) +
  coord_flip() +
  labs(x = "Land Cover", y = "Average Area of Land Cover Class Parcels (ha)") +
  theme_bw() +
  theme(panel.border = element_rect(colour = "black", fill=NA, size=1))

mean_area_merge_obs_p

parcel_count_merge_obs_p <- ggplot(data = area_merge_obs, aes(x = reorder(NewClass, obs_count), y = obs_count)) +
  geom_point() + 
  coord_flip() +
  labs(x = "Land Cover", y = "Number of Parcels in Land Cover Class ()") +
  theme_bw() +
  theme(panel.border = element_rect(colour = "black", fill=NA, size=1))

parcel_count_merge_obs_p
```

```{r}
# plot the average and the standard error
allpolys_lc_expbats_mean <- ggplot(data = extract_merge_obs, aes(x = reorder(NewClass, Mean), y = Mean)) + 
  geom_point() +
  geom_errorbar(aes(ymin=Mean-LC_95perc, ymax=Mean+LC_95perc)) +
  coord_flip() + 
  labs(x = "Land Cover", y = "Average Bat Presence") +
  theme_bw() +
  theme(panel.border = element_rect(colour = "black", fill=NA, size=1))

allpolys_lc_expbats_mean
```